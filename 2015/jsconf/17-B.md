# Zombies and Soup: Why End-to-End testing sucks (and why it doesn't have to)([@geek_dave](https://twitter.com/geek_dave))



## How to Draw a Horse:

* Five step process where you add details and you end up withah beautiful horse. what happens between steps 4 and 5? And why is technology ilke this? why is testing technology like this?
* Speaker calls things like this the "troll" README.
  Lots of content paints a rosy picture of a thing.
* End-to-end testing is a lot like this.



## Speaker works at Walmart Labs doing infrastructure, build, and automation tools for Walmart.com

* Test Pyramid: Lots of unit tests, fewer "service" tests, fewer still "UI" tests.
* We're here to talk about UI tests (not necessarily UI, but end-to-end tests).
* end-to-end tests make sure that none of the emergent gaps are show-stoppers.
* it's a pain to run end-to-end tests over-and-over on all browsers.
* it's even _more_ painful to revisit all of code later to find that someone has introduced a bug in the last month or so.
* everyone seems to rely on selenium for end-to-end testing.
  * selenium is powerful, not necessarily easy to use.
  * we seem to end up at a big rube goldberg machine situation.
  * If you start down this paith, you will find that tests sometimes fail for no good reason creating false positive results. also known as "test flake".
  * TTL podcast - check it out.



## Automation Goals:

* Non-technical people should be able to write these (dev and QA should write)
* Fast
* No tolerance for false positives


For first goal, tried 'Nightwatch'. Worked nicely at first, but ended up
with the same scenario.



## End-to-End tests are NOT like unit tests.

* can of soup when you're hungry is like a test result.
  * unit tests: just go grab the can from the cupboard. quick, easy, there.
  * end-to-end tests: get in your car, drive through zombie apocalypse, get to store, fight for soup (assuming there's soup there), fight through zombies more

* There are bugs in the selenium webdrivers.
* The network could be flaky.
* The services themselves (e.g. Sauce) could have bugs/outages

^^ seemed like a whack-a-mole problem.


So what do we do?


* Re-think the assumptions. Where do we start, what is the axiom?
* oh my god, assert multiple times. jesus, now we're using jQuery clicks instead of selenium webdriver clicks.
* they gained momentum and smoothed over bumps in some ugly, non-optimal ways.
* "not all problems require precision solutions. sometimes you just need to smooth them over."
* they finally got to a point where the tests are reliably passing/failing. with lots of duct tape.
  * "this is not suitable to release as open source."
  * "what's the responsible thing to do here? Can we take our effort
     and make it useful to others?"
* google said "just say no to end-to-end testing", but e2e can be significantly faster if you can parallelize the tests.
* lots of people got stuck on the flaky stuff, walmart labs but duct tape on it and enabled themselves to move on to other things.
* tests are flaky. but where are they flaky? If it's one particular test (or one particular browser), and you can isolate that, you can investigate componentsn of these things to try to find a fix.
* WML wants to open source this (code-name Magellan, currently in legal review before its opened) - massively parallel, has duct tape.

## #SSaSS - Shoveling Shit as a Service.

* Momentum is greater than perfection. Getting stuck is demoralizing and unproductive.
* Smoothing things over is better than giving up. Effort gets wasted when people _need_ a clean solution.
* Useful is better than precise.
* Open Source is better than Closed Source (even when it's ugly). Release it as soon as it's _useful_.
* TTL podcast: Magellan was discussed.
